# 进程与线程

对于有线程系统：

- 进程是资源分配的独立单位
- 线程是资源调度的独立单位

对于无线程系统：

- 进程是资源调度、分配的独立单位

## 进程之间的通信方式以及优缺点

- 管道（PIPE）
  - 有名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信
    - 优点：可以实现任意关系的进程间的通信
    - 缺点：
      1. 长期存于系统中，使用不当容易出错
      2. 缓冲区有限
  - 无名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）
    - 优点：简单方便
    - 缺点：
      1. 局限于单向通信
      2. 只能创建在它的进程以及其有亲缘关系的进程之间
      3. 缓冲区有限
- 信号量（Semaphore）：一个计数器，可以用来控制多个线程对共享资源的访问
  - 优点：可以同步进程
  - 缺点：信号量有限
- 信号（Signal）：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生
- 消息队列（Message Queue）：是消息的链表，存放在内核中并由消息队列标识符标识
  - 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便
  - 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合
- 共享内存（Shared Memory）：映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问
  - 优点：无须复制，快捷，信息量大
  - 缺点：
    1. 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
    2. 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信
- 套接字（Socket）：可用于不同及其间的进程通信
  - 优点：
    1. 传输数据为字节级，传输数据可自定义，数据量小效率高
    2. 传输数据时间短，性能高
    3. 适合于客户端和服务器端之间信息实时交互
    4. 可以加密,数据安全性强
  - 缺点：需对传输的数据进行解析，转化成应用级的数据。

## 线程之间的通信方式



![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-18-2.png)

- 锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
  - 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
  - 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。
  - 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持着是否已经释放锁。
  - 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制(Semaphore)
  - 无名线程信号量
  - 命名线程信号量
- 信号机制(Signal)：类似进程间的信号处理
- 屏障（barrier）：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制

**进程之间私有和共享的资源**

- 私有：地址空间、堆、全局变量、栈、寄存器
- 共享：代码段，公共数据，进程目录，进程 ID

**线程之间私有和共享的资源**

- 私有：线程栈，寄存器，程序寄存器
- 共享：堆，地址空间，全局变量，静态变量

## 多进程与多线程间的对比、优劣与选择

### 对比

| 对比维度       | 多进程                                                       | 多线程                                                       | 总结     |
| :------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :------- |
| 数据共享、同步 | 数据共享复杂，需要用 IPC；数据是分开的，同步简单             | 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 | 各有优势 |
| 内存、CPU      | 占用内存多，切换复杂，CPU 利用率低                           | 占用内存少，切换简单，CPU 利用率高                           | 线程占优 |
| 创建销毁、切换 | 创建销毁、切换复杂，速度慢                                   | 创建销毁、切换简单，速度很快                                 | 线程占优 |
| 编程、调试     | 编程简单，调试简单                                           | 编程复杂，调试复杂                                           | 进程占优 |
| 可靠性         | 进程间不会互相影响                                           | 一个线程挂掉将导致整个进程挂掉                               | 进程占优 |
| 分布式         | 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 | 适应于多核分布式                                             | 进程占优 |

### 优劣

| 优劣 | 多进程                                   | 多线程                                   |
| :--- | :--------------------------------------- | :--------------------------------------- |
| 优点 | 编程、调试简单，可靠性较高               | 创建、销毁、切换速度快，内存、资源占用小 |
| 缺点 | 创建、销毁、切换速度慢，内存、资源占用大 | 编程、调试复杂，可靠性较差               |

### 选择

- 需要频繁创建销毁的优先用线程
- 需要进行大量计算的优先使用线程
- 强相关的处理用线程，弱相关的处理用进程
- 可能要扩展到多机分布的用进程，多核分布的用线程
- 都满足需求的情况下，用你最熟悉、最拿手的方式

线程和进程的区别？

- 调度：线程是调度的基本单位（PC，状态码，通用寄存器，线程栈及栈指针）；进程是拥有资源的基本单位（打开文件，堆，静态区，代码段等）。
- 并发性：一个进程内多个线程可以并发（最好和CPU核数相等）；多个进程可以并发。
- 拥有资源：线程不拥有系统资源，但一个进程的多个线程可以共享隶属进程的资源；进程是拥有资源的独立单位。
- 系统开销：线程创建销毁只需要处理PC值，状态码，通用寄存器值，线程栈及栈指针即可；进程创建和销毁需要重新分配及销毁task_struct结构。

## 进程

### 进程的切换状态

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@4.5/202105/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-13-1-%E6%9B%B4%E6%94%B9%E7%89%88.png)

- 就绪状态（ready）：等待被调度
- 运行状态（running）
- 阻塞状态（waiting）：等待资源
  - 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
  - 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

> 多进程与多线程间的对比、优劣与选择来自：[多线程还是多进程的选择及区别](https://blog.csdn.net/lishenglong666/article/details/8557215)

### 进程同步的四种方法？



临界区，同步与互斥，信号量，管程



### 父子进程

子进程从父进程继承的有：

1.进程的资格(真实(real)/有效(effective)/已保存(saved)用户号(UIDs)和组号(GIDs))

2.环境(environment)

3.堆栈

4.内存

5.进程组号

独有：

1.进程号；

2.不同的父进程号(译者注：即子进程的父进程号与父进程的父进程号不同， 父进程号可由getppid函数得到)；

3.资源使用(resource utilizations)设定为0



## 进程间的通信方式

### 管道

linux

`netstat -tulnp | grep 8080`

把 netstat -tulnp 的输出结果作为 grep 8080 这条命令的输入，|   匿名管道

管道，把前一条命令的输出作为后一条的输入。管道通信，是单向的



#### 命名管道



创建名字为test的命名管道

`mkfifo test`

用一个进程向这个管道写数据，然后另外一个进程把里面数据读出来

`echo "this is a pipe">test`写入数据

读数据`cat<test`

管道的通知机制类似于缓存，就像把一个进程把数据放在某个缓存区域，然后等这另外一个进程去拿，并且管道都是单向传输的

效率比较低下



### 消息队列



a进程要给b进程发送消息，只需要把消息放在对应的消息队列里面就行了，b需要就去获取

b也类似类似与缓存

缺点：

如果 a 进程发送的数据占的内存比较大，并且两个进程之间的通信特别频繁的话，消息队列模型就不大适合了。因为 a 发送的数据很大的话，意味**发送消息（拷贝）**这个过程需要花很多时间来读内存。

### 共享内存

解决拷贝的时间

系统加载一个进程的时候，分配给进程的内存并不是实际的物理内存，而是虚拟内存空间。让两个进程各拿出一块虚拟地址空间，然后映射到相同的物理内存中，

两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了**内存共享**机制了。



### 信号量

共享内存最大的问题是什么？没错，就是多进程竞争内存的问题，就像类似于我们平时说的**线程安全**问题。如何解决这个问题？这个时候我们的**信号量**就上场了。

信号量的本质就是一个计数器，用来实现进程之间的互斥与同步。例如信号量的初始值是 1，然后 a 进程来访问**内存1**的时候，我们就把信号量的值设为 0，然后进程b 也要来访问**内存1**的时候，看到信号量的值为 0 就知道已经有进程在访问**内存1**了，这个时候进程 b 就会访问不了**内存1**。所以说，信号量也是进程之间的一种通信方式。

### socket

上面我们说的共享内存、管道、信号量、消息队列，他们都是多个进程在一台主机之间的通信，那两个相隔几千里的进程能够进行通信吗？

答是必须的，这个时候 Socket 这家伙就派上用场了，例如我们平时通过浏览器发起一个 http 请求，然后服务器给你返回对应的数据，这种就是采用 Socket 的通信方式了。



## 进程的组成部分

linux环境下主要控制块包括：进程标识符（即进程ID），进程当前状态，相应的进程控制信息。

地址空间可以分为：

文本段：存放相应的程序代码

用户数据段：存放相应的程序处理数据

系统数据段：存放相应的程序运行环境



## 进程的基本状态

创建，就绪，执行，等待和终止



## 进程的上下文可分为几部分？

用户级上下文：正文，数据，用户堆栈以及共享存储区

寄存器上下文：通用寄存器，程序寄存器ip，处理器状态寄存器EFLAGS，栈指针ESP

系统级上下文：进程控制块，内存管理信息，内核栈



## 进程调度算法

- 先来先服务(FCFS)：有利于长进程、CPU繁忙的进程，不利于短进程、I/O繁忙的进程；
- 短作业优先(SJF)：对预计执行时间短的进程优先分派处理机，通常后来的短进程不抢先正在执行的进程；相比于FCFS算法，SJF可以改善平均周转时间和平均带权周转时间，缩短进程的等待时间，提高系统的吞吐量，但是不利于长进程，而且未能根据进程的紧迫程度来划分优先级，以及难以准确估计进程的执行时间，从而影响性能；
- 最高响应比优先(HRRN)：FCFS只考虑等待时间，SJF只考虑执行时间，而HRRN同时考虑每个作业的等待时间和执行时间，定义响应比$R=(W+T)=1+W/T$，其中$W$为等待时间，$T$为执行时间；由于每次调度前都要计算响应比，系统开销相应增加；
- 时间片轮转(RR)：使得进程以FCFS的方式按时间片轮流使用CPU，每次调度时将CPU分派给队首进程，让其执行一个时间片，其长度从几ms到几百ms，当一个时间片结束时，发生时钟中断，调度程序据此暂停当前进程的执行，将其送到就绪队列的末尾，使其出让CPU，并通过上下文切换执行当前的队首进程；不利于处理紧急作业，而且时间片的大小对系统性能的影响很大，因此时间片的大小应适当；
  - 那么应该如何确定时间片的大小？
    - 系统对响应时间的要求；
    - 就绪队列中进程的时间；
    - 系统的处理能力；
- 多级反馈队列(MFQ)：进程在不同优先级的队列间迁移，首先调度优先级高的队列中的进程，只有优先级高的队列为空时才去调度优先级低的队列中的进程；对于同一个队列中的进程，按照时间片轮转的方式进行调度，如果N个时间片后依然未能完成，则进入优先级低的队列等待；在低优先级的队列中的进程在运行时，又有新到达的作业，那么在运行完这个时间片后，CPU分配给新到达的作业，即抢占式。

## 什么是孤儿进程？什么是僵尸进程？僵尸进程有什么危害？如何解决？

父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程，将被`init`进程（进程号为1）所收养，并由`init`进程对这些子进程完成状态收集工作；



僵尸进程：一个进程使用`fork`创建子进程，如果子进程退出，而父进程并未调用`wait`或`waitpid`来获取子进程的状态信息，子进程的进程描述符仍然保存在系统中，那么这种子进程将成为僵尸进程。



僵尸进程的危害：在子进程退出的时候，内核释放该子进程所有的资源，但仍保留进程号、退出状态、运行时间等信息，直到父进程通过`wait`或`waitpid`对其进行释放；但如果父进程不对保留信息进行释放，进程号会一直被占用，然而系统所能使用的进程号是有限的，如果产生大量的僵尸进程，系统将因没有可用的进程号而导致系统不能产生新的进程。

解决僵尸进程的方法：

- 父进程通过`wait`和`waitpid`等函数等待子进程结束，但这样会导致父进程挂起；
- 如果父进程很忙，那么可用`signal`函数为`SIGCHLD`安装`handler`，这样当子进程结束后，父进程会收到信号，在`handler`中调用`wait`回收；
- 如果父进程不关心子进程何时结束，那么可以用`signal(SIGCHLD, SIG_IGN)`通知内核，这样当子进程结束后，内核会对其进行回收；
- `fork`两次，父进程`fork`一个子进程后继续工作，子进程`fork`一个孙进程后退出，那么孙进程将被`init`接管，这样当子进程结束后，内核会对其进行回收。

## 单线程处理高并发

在单线程模型中，采用多路复用I/O来提高单线程处理多个请求的能力，然后采用事件驱动模型。基于异步回调来处理事件



# 程序编译与链接

**预编译** 主要处理源代码文件中的以“#”开头的预编译指令。

**编译** 把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。

**汇编**

**链接**

**1、静态链接：** 函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。 空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本； 更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。

运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。

**2、动态链接：** 动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。

共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多份副本，而是这多个程序在执行时共享同一份副本；

更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。

性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。



逻辑地址与物理地址的转换

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-15-1.png)





# Linux 内核的同步方式

## 原因

在现代操作系统里，同一时间可能有多个内核执行流在执行，因此内核其实象多进程多线程编程一样也需要一些同步机制来同步各执行单元对共享数据的访问。尤其是在多处理器系统上，更需要一些同步机制来同步不同处理器上的执行单元对共享的数据的访问。



- POSIX信号量：可用于进程同步，也可用于线程同步。
- POSIX互斥锁 + 条件变量：只能用于线程同步。

## 同步方式

- 原子操作
- 信号量（semaphore）
- 读写信号量（rw_semaphore）
- 自旋锁（spinlock）
- 大内核锁（BKL，Big Kernel Lock）
- 读写锁（rwlock）
- 大读者锁（brlock-Big Reader Lock）
- 读-拷贝修改(RCU，Read-Copy Update)
- 顺序锁（seqlock）

> 来自：[Linux 内核的同步机制，第 1 部分](https://www.ibm.com/developerworks/cn/linux/l-synch/part1/)、[Linux 内核的同步机制，第 2 部分](https://www.ibm.com/developerworks/cn/linux/l-synch/part2/)



# 动态分区分配算法有哪几种？可以分别说说吗？

## [1、首次适应算法](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=1、首次适应算法)

算法思想：每次都从低地址开始查找，找到第–个能满足大小的空闲分区。

如何实现：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链( 或空闲分[表)，找到大小能满足要求的第-一个空闲分区。

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-11-1.png)

## [2、最佳适应算法](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=2、最佳适应算法)

算法思想:由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区,即，优先使用更小的空闲区。

如何实现:空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。 ![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-11-2.png)

## [3、最坏适应算法](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=3、最坏适应算法)

又称最大适应算法(Largest Fit)

算法思想:为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。

如何实现:空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。 ![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-11-3.png)

## [4、邻近适应算法](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=4、邻近适应算法)

算法思想：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。

如何实现：空闲分区以地址递增的顺序排列(可排成-一个循环链表)。每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。 ![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-11-4.png)

## [5、总结](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=5、总结)

首次适应不仅最简单，通常也是最好最快，不过首次适应算法会使得内存低地址部分出现很多小的空闲分区，而每次查找都要经过这些分区，因此也增加了查找的开销。邻近算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间分裂成小的碎片，它通常比首次适应算法结果要差。

最佳导致大量碎片，最坏导致没有大的空间。

进过实验，首次适应比最佳适应要好，他们都比最坏好。

| 算法     | 算法思想                                           | 分区排列顺序                                 | 优点                                                         | 缺点                                                         |
| :------- | :------------------------------------------------- | :------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| 首次适应 | 从头到尾找适合的分区                               | 空闲分区以地址递增次序排列                   | 综合看性能最好。**算法开销小**，回收分区后一.般不需要对空闲分区队列重新排序 |                                                              |
| 最佳适应 | 优先使用更小的分区，以保留更多大分区               | 空闲分区以容量递增次序排列                   | 会有更多的大分区被保留下来，更能满足大进程需求               | 会产生很多太小的、难以利用的碎片;**算法开销大**，回收分区后可能需要对空闲分区队列重新排序 |
| 最坏适应 | 优先使用更大的分区，以防止产生太小的不可用的碎片   | 空闲分区以容量递减次序排列                   | 可以减少难以利用的小碎片                                     | 大分区容易被用完，不利于大进程;**算法开销大**(原因同上)      |
| 邻近适应 | 由首次适应演变而来，每次从上次查找结束位置开始查找 | 空闲分区以地址递增次序排列(可排列成循环链表) | 不用每次都从低地址的小分区开始检索。**算法开销小**(原因同首次适应算法) | 会使高地址的大分区也被用完                                   |



## 虚拟技术

虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

多进程与多线程：多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。



# 锁

## 经典锁

读写锁

互斥锁

条件变量

​	条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说**互斥锁是线程间互斥的机制，条件变量则是同步机制。**

自旋锁

如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时期占有锁，那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。

## 死锁

### 原因

- 系统资源不足
- 资源分配不当
- 进程运行推进顺序不合适

### 产生条件

- 互斥
- 请求和保持
- 不剥夺
- 环路

### 预防

- 打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造。
- 打破不可抢占条件：当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。
- 打破占有且申请条件：采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。
- 打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源。
- 有序资源分配法
- 银行家算法

# 文件系统

- Windows：FCB 表 + FAT + 位图
- Unix：inode + 混合索引 + 成组链接



# 内存

## **内存分配方式**

（1） 从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。

（2） 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。

（3） 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

## [内存交换你知道有哪些需要注意的关键点吗？](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=55、内存交换你知道有哪些需要注意的关键点吗？)

1. 交换需要备份存储，通常是快速磁盘，它必须足够大，并且提供对这些内存映像的直接访问。
2. 为了有效使用CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间，转移时间与所交换的空间内存成正比。
3. 如果换出进程，比如确保该进程的内存空间成正比。
4. 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。
5. 交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。
6. 普通交换使用不多，但交换的策略的某些变种在许多系统中（如UNIX系统）仍然发挥作用。

## [系统并发和并行，分得清吗？](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=56、系统并发和并行，分得清吗？)

并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。

并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

操作系统通过引入进程和线程，使得程序能够并发运行。



# 主机字节序与网络字节序

## 主机字节序（CPU 字节序）

### 概念

主机字节序又叫 CPU 字节序，其不是由操作系统决定的，而是由 CPU 指令集架构决定的。主机字节序分为两种：

- 大端字节序（Big Endian）：高序字节存储在低位地址，低序字节存储在高位地址
- 小端字节序（Little Endian）：高序字节存储在高位地址，低序字节存储在低位地址

## 存储方式

32 位整数 `0x12345678` 是从起始位置为 `0x00` 的地址开始存放，则：

| 内存地址 | 0x00 | 0x01 | 0x02 | 0x03 |
| :------- | :--- | :--- | :--- | :--- |
| 大端     | 12   | 34   | 56   | 78   |
| 小端     | 78   | 56   | 34   | 12   |

## 各架构处理器的字节序

- x86（Intel、AMD）、MOS Technology 6502、Z80、VAX、PDP-11 等处理器为小端序；
- Motorola 6800、Motorola 68000、PowerPC 970、System/370、SPARC（除 V9 外）等处理器为大端序；
- ARM（默认小端序）、PowerPC（除 PowerPC 970 外）、DEC Alpha、SPARC V9、MIPS、PA-RISC 及 IA64 的字节序是可配置的。

## 网络字节序

网络字节顺序是 TCP/IP 中规定好的一种数据表示格式，它与具体的 CPU 类型、操作系统等无关，从而可以保重数据在不同主机之间传输时能够被正确解释。

网络字节顺序采用：大端（Big Endian）排列方式。

# 页面置换算法

在地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。

## 分类

- 全局置换：在整个内存空间置换
- 局部置换：在本进程中进行置换

## 算法

全局：

- 工作集算法
- 缺页率置换算法

局部：

- 最佳置换算法（OPT）
- 先进先出置换算法（FIFO）
- 最近最久未使用（LRU）算法
- 时钟（Clock）置换算法



# [服务器高并发的解决方案你知道多少？](https://interviewguide.cn/#/Doc/Knowledge/操作系统/操作系统?id=65、服务器高并发的解决方案你知道多少？)

- 应用数据与静态资源分离 将静态资源（图片，视频，js，css等）单独保存到专门的静态资源服务器中，在客户端访问的时候从静态资源服务器中返回静态资源，从主服务器中返回应用数据。
- 客户端缓存 因为效率最高，消耗资源最小的就是纯静态的html页面，所以可以把网站上的页面尽可能用静态的来实现，在页面过期或者有数据更新之后再将页面重新缓存。或者先生成静态页面，然后用ajax异步请求获取动态数据。
- 集群和分布式 （集群是所有的服务器都有相同的功能，请求哪台都可以，主要起分流作用）
  （分布式是将不同的业务放到不同的服务器中，处理一个请求可能需要使用到多台服务器，起到加快请求处理的速度。）
  可以使用服务器集群和分布式架构，使得原本属于一个服务器的计算压力分散到多个服务器上。同时加快请求处理的速度。
- 反向代理 在访问服务器的时候，服务器通过别的服务器获取资源或结果返回给客户端。